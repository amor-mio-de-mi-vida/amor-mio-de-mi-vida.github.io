<!DOCTYPE html><html lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="amor mío de mi vida">
    
    <title>
        
            Programming Model |
        
        Hesen's Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
        <link rel="shortcut icon" href="/images/avatar.svg">
    
    
<link rel="stylesheet" href="/font/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/font/css/regular.min.css">

    
<link rel="stylesheet" href="/font/css/solid.min.css">

    
<link rel="stylesheet" href="/font/css/brands.min.css">

    
    <script class="keep-theme-configurations">
    const KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.xml"}
    KEEP.theme_config = {"title":"Keep","subtitle":"Hexo theme keep quick starter","description":"","keywords":null,"author":"Keep Team","language":"en","timezone":"","url":"http://example.com","permalink":":year/:month/:day/:name/","permalink_defaults":null,"pretty_urls":{"trailing_index":true,"trailing_html":true},"source_dir":"source","public_dir":"public","tag_dir":"tags","archive_dir":"archives","category_dir":"categories","code_dir":"downloads/code","i18n_dir":":lang","skip_render":null,"new_post_name":":title.md","default_layout":"post","titlecase":false,"external_link":{"enable":true,"field":"site","exclude":""},"filename_case":0,"render_drafts":false,"post_asset_folder":false,"relative_link":false,"future":true,"highlight":{"enable":true,"line_number":true,"auto_detect":false,"tab_replace":"","wrap":true,"hljs":false},"prismjs":{"enable":false,"preprocess":true,"line_number":true,"tab_replace":""},"index_generator":{"path":"","per_page":10,"order_by":"-date"},"default_category":"uncategorized","category_map":null,"tag_map":null,"meta_generator":true,"date_format":"YYYY-MM-DD","time_format":"HH:mm:ss","updated_option":"mtime","per_page":10,"pagination_dir":"page","include":null,"exclude":null,"ignore":null,"theme":"keep","deploy":{"type":""},"search":{"path":"search.json","field":"post","content":true,"format":"striptags"},"feed":{"type":"atom","path":"atom.xml","limit":20},"math":{"perpage":true,"mathjax":{"enable":true,"mhchem":false}},"root":"","base_info":{"primary_color":"#0066cc","title":"Hesen's Blog","author":"amor mío de mi vida","avatar":"/images/avatar.svg","logo":"/images/avatar.svg","favicon":"/images/avatar.svg"},"menu":{"home":"/                       || fa-solid fa-home","archives":"/archives           || fa-solid fa-box-archive","tags":"/tags                   || fa-solid fa-tags","categories":"/categories       || fa-solid fa-layer-group","about":"/about                 || fa-solid fa-user","github":"https://github.com/amor-mio-de-mi-vida || fa-brands fa-github"},"first_screen":{"enable":true,"background_img":"/images/bg.svg","background_img_dark":"/images/bg.svg","description":"Audentis fortuna iuvat.","hitokoto":false},"social_contact":{"enable":true,"links":{"github":"https://github.com/amor-mio-de-mi-vida","weixin":"img |","qq":null,"weibo":null,"zhihu":null,"twitter":null,"x":null,"facebook":null,"email":null}},"scroll":{"progress_bar":false,"percent":true,"hide_header":true},"home":{"announcement":null,"category":true,"tag":true,"post_datetime":"updated"},"post":{"author_badge":{"enable":true,"level_badge":true,"custom_badge":["One","Two","Three"]},"word_count":{"wordcount":true,"min2read":true},"datetime_format":"YYYY-MM-DD HH:mm:ss","copyright_info":true,"share":true,"reward":{"enable":false,"img_link":null,"text":null}},"code_block":{"tools":{"enable":true,"style":"default"},"highlight_theme":"default"},"toc":{"enable":true,"number":false,"expand_all":true,"init_open":true,"layout":"right"},"website_count":{"busuanzi_count":{"enable":true,"site_uv":true,"site_pv":true,"page_pv":true}},"local_search":{"enable":true,"preload":true},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.36"},"waline":{"server_url":null,"reaction":false,"version":"3.2.1"},"giscus":{"repo":null,"repo_id":null,"category":"Announcements","category_id":null,"reactions_enabled":false},"artalk":{"server":null},"disqus":{"shortname":null}},"rss":{"enable":false},"lazyload":{"enable":true},"cdn":{"enable":false,"provider":"cdnjs"},"pjax":{"enable":true},"footer":{"since":2020,"word_count":false,"site_deploy":{"enable":false,"provider":"github","url":null},"record":{"enable":false,"list":[{"code":null,"link":null}]}},"inject":{"enable":false,"css":[null],"js":[null]},"source_data":{},"version":"4.2.3"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original post title","author":"Original post author","link":"Original post link"}
  </script>
<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i>
    
</div>



<main class="page-container border-box">
    <!-- home first screen  -->
    

    <!-- page content -->
    <div class="page-main-content border-box">
        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="border-box header-content">
        <div class="left flex-start border-box">
            
                <a class="logo-image border-box" href="/">
                    <img src="/images/avatar.svg">
                </a>
            
            <a class="site-name border-box" href="/">
               Hesen's Blog
            </a>
        </div>

        <div class="right border-box">
            <div class="pc border-box">
                <ul class="menu-list border-box">
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-home"></i>
                                
                                HOME
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/archives">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-box-archive"></i>
                                
                                ARCHIVES
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/tags">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-tags"></i>
                                
                                TAGS
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/categories">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-layer-group"></i>
                                
                                CATEGORIES
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/about">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-user"></i>
                                
                                ABOUT
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" target="_blank" rel="noopener" href="https://github.com/amor-mio-de-mi-vida">
                                
                                    <i class="menu-text-color menu-icon fa-brands fa-github"></i>
                                
                                GITHUB
                                
                            </a>
                            
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="menu-text-color fas search fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile border-box flex-start">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list border-box">
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-home"></i>
                                </span>
                            
                            HOME
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/archives">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-box-archive"></i>
                                </span>
                            
                            ARCHIVES
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/tags">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-tags"></i>
                                </span>
                            
                            TAGS
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/categories">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-layer-group"></i>
                                </span>
                            
                            CATEGORIES
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/about">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-user"></i>
                                </span>
                            
                            ABOUT
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" target="_blank" rel="noopener" href="https://github.com/amor-mio-de-mi-vida">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-brands fa-github"></i>
                                </span>
                            
                            GITHUB
                        </a>
                        
                    </label>
                    
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle border-box">

            <div class="main-content border-box">
                

                    
<div class="fade-in-down-animation">
    <div class="post-page-container border-box">
        <div class="post-content-container border-box">
            

            <div class="post-content-bottom border-box">
                
                    <div class="post-title">
                        Programming Model
                    </div>
                

                
                    <div class="post-header border-box">
                        
                            <div class="avatar-box border-box">
                                <img src="/images/avatar.svg">
                            </div>
                        
                        <div class="info-box">
                            <div class="author border-box">
                                <span class="name">amor mío de mi vida</span>
                                
                                    <span class="author-badge">Lv3</span>
                                
                            </div>
                            <div class="meta-info border-box">
                                

<div class="post-meta-info-container border-box post">
    <div class="post-meta-info border-box">
        

        
            <span class="meta-info-item post-create-date">
                <i class="icon fa-solid fa-calendar-plus"></i>&nbsp;
                <span class="datetime">2024-10-16 20:35:39</span>
            </span>

            <span class="meta-info-item post-update-date">
                <i class="icon fa-solid fa-file-pen"></i>&nbsp;
                <span class="datetime" data-updated="Wed Oct 16 2024 22:34:09 GMT+0800">2024-10-16 22:34:09</span>
            </span>
        

        

        

        
        
            <span class="meta-info-item post-wordcount">
                <i class="icon fas fa-file-word"></i>&nbsp;<span>6.7k Words</span>
            </span>
        
        
            <span class="meta-info-item post-min2read">
                <i class="icon fas fa-clock"></i>&nbsp;<span>26 Mins</span>
            </span>
        
        
            <span class="meta-info-item post-pv">
                <i class="icon fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
            </span>
        
    </div>

    
</div>

                            </div>
                        </div>
                    </div>
                

                <div class="post-content keep-markdown-body ">
                    

                    
                         <h1 id="programming-model">Programming Model</h1>
<h2 id="kernels">Kernels</h2>
<p>CUDA
C++通过允许程序员定义称为内核的C++函数来扩展C++，这些函数在被调用时，由N个不同的CUDA线程并行执行N次，这与只执行一次的常规C++函数不同。</p>
<p>内核是通过使用<code>__global__</code>声明说明符定义的，并且给定内核调用的执行该内核的CUDA线程数是通过使用新的<code>&lt;&lt;&lt;...&gt;&gt;&gt;</code>执行配置语法指定的（参见C++语言扩展）。执行内核的每个线程都被赋予一个唯一的线程ID，这个ID可以通过内置变量在内核内部访问。</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Kernel definition</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">VecAdd</span><span class="params">(<span class="type">float</span>* A, <span class="type">float</span>* B, <span class="type">float</span>* C)</span> </span>{</span><br><span class="line">	<span class="type">int</span> i = threadIdx.x;</span><br><span class="line">	C[i] = A[i] + B[i];</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">	...</span><br><span class="line">	<span class="comment">// Kernel invocation with N threads</span></span><br><span class="line">	VecAdd&lt;&lt;&lt;<span class="number">1</span>, N&gt;&gt;&gt;(A, B, C);</span><br><span class="line">	...</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="thread-hierarchy">Thread Hierarchy</h2>
<p>为了方便起见，threadIdx是一个三维向量，因此可以使用一维、二维或三维的线程索引来识别线程，形成一维、二维或三维的线程块，称为线程块。这提供了一种自然的方式来在诸如向量、矩阵或体积等域的元素上调用计算。</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="function">Kernel definition</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatAdd</span><span class="params">(<span class="type">float</span> A[N][N], <span class="type">float</span> B[N][N], <span class="type">float</span> C[N][N])</span> </span>{</span><br><span class="line">	<span class="type">int</span> i = threadIdx.x;</span><br><span class="line">	<span class="type">int</span> j = threadIdx.y;</span><br><span class="line">	C[i][j] = A[i][j] + B[i][j];</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">	...</span><br><span class="line">	<span class="comment">// Kernel invocation with one block of N * N * 1 threads</span></span><br><span class="line">	<span class="type">int</span> numBlocks = <span class="number">1</span>;</span><br><span class="line">	<span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(N, N)</span></span>;</span><br><span class="line">	MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);</span><br><span class="line">	...</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>线程块中的线程数量是有限制的，因为一个块中的所有线程都预期驻留在同一个流处理器核心上，并且必须共享该核心有限的内存资源。在当前的GPU上，一个线程块可以包含最多1024个线程。</p>
<p><img lazyload="" alt="image" data-src="https://github.com/amor-mio-de-mi-vida/picx-images-hosting/raw/master/cuda/image.99tcd9b9ql.webp"></p>
<p>然而，一个 <code>kernel</code>
可以被多个形状相同的线程块执行，因此总线程数等于每个块的线程数乘以块的数量。<code>grid</code>中的每个块可以通过一维、二维或三维的唯一索引来识别，该索引在内核中可以通过内置的blockIdx变量访问。线程块的维度在内核中可以通过内置的blockDim变量访问。&nbsp;将先前的MatAdd()示例扩展到处理多个块，代码如下所示。</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Kernel definition</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatAdd</span><span class="params">(<span class="type">float</span> A[N][N], <span class="type">float</span> B[N][N], <span class="type">float</span> C[N][N])</span> </span>{</span><br><span class="line">	<span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">	<span class="type">int</span> j = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">	<span class="keyword">if</span> (i &lt; N &amp;&amp; j &lt; N)</span><br><span class="line">		C[i][j] = A[i][j] + B[i][j];</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">	...</span><br><span class="line">	<span class="comment">// Kernel invocation</span></span><br><span class="line">	<span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span></span>;</span><br><span class="line">	<span class="function">dim3 <span class="title">numBlocks</span><span class="params">(N ∕ threadsPerBlock.x, N ∕ threadsPerBlock.y)</span></span>;</span><br><span class="line">	MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);</span><br><span class="line">	...</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>线程块需要独立执行：它们必须能够以任何顺序执行，无论是并行还是串行。这种独立性的要求允许线程块在任何数量的核心上以任何顺序调度。</p>
<p>块内的线程可以通过共享内存共享数据，并通过同步它们的执行来协调内存访问。更准确地说，可以在内核中通过调用__syncthreads()内置函数指定同步点；<code>__syncthreads()</code>
充当一个屏障，块中的所有线程都必须在此处等待，然后才能继续执行。共享内存给出了使用共享内存的一个例子。除了<code>__syncthreads()</code>之外，协作组API还提供了一套丰富的线程同步原语。</p>
<p>为了高效协作，共享内存预计是位于每个处理器核心附近的低延迟内存（类似于L1缓存），并且<code>__syncthreads()</code>预计是轻量级的。</p>
<p><img lazyload="" alt="image" data-src="https://github.com/amor-mio-de-mi-vida/picx-images-hosting/raw/master/cuda/image.3uutuu2kn0.webp"></p>
<p>随着NVIDIA计算能力9.0的引入，CUDA编程模型引入了一个可选的层次结构级别，称为线程块集群，由线程块组成。类似于线程块中的线程被保证在一个流处理器上共同调度，集群中的线程块也被保证在GPU的处理簇（GPU
Processing Cluster，简称GPC）上共同调度。</p>
<p>类似于线程块，集群也组织成一维、二维或三维，如线程块集群<code>grid</code>所示。集群中的线程块数量可以由用户定义，CUDA支持的最大集群大小为8个线程块，作为可移植的集群大小。请注意，在无法支持8个多处理器的GPU硬件或MIG配置上，最大集群大小将相应减少。识别这些较小配置以及支持超过8个线程块集群大小的大型配置是特定于架构的，可以使用<code>cudaOccupancyMaxPotentialClusterSize</code>
API进行查询。</p>
<p>线程块集群可以在内核中使用编译时内核属性&nbsp;<code>__cluster_dims__(X,Y,Z)</code>&nbsp;启用，或者使用
CUDA 内核启动
API&nbsp;<code>cudaLaunchKernelEx</code>。下面的例子展示了如何使用编译时内核属性启动一个集群。使用内核属性设置的集群大小在编译时是固定的，然后可以使用传统的&nbsp;<code>&lt;&lt;&lt; &gt;&gt;&gt;</code>&nbsp;启动内核。如果一个内核使用编译时的集群大小，那么在启动内核时不能修改集群大小。</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Kernel definition</span></span><br><span class="line"><span class="comment">// Compile time cluster size 2 in X-dimension and 1 in Y and Z dimension</span></span><br><span class="line">__global__ <span class="type">void</span> __cluster_dims__(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="built_in">cluster_kernel</span>(<span class="type">float</span> *input, <span class="type">float</span>* output) {</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">	<span class="type">float</span> *input, *output;</span><br><span class="line">	<span class="comment">// Kernel invocation with compile time cluster size</span></span><br><span class="line">	<span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span></span>;</span><br><span class="line">	<span class="function">dim3 <span class="title">numBlocks</span><span class="params">(N ∕ threadsPerBlock.x, N ∕ threadsPerBlock.y)</span></span>;</span><br><span class="line">	<span class="comment">// The grid dimension is not affected by cluster launch, and is still enumerated</span></span><br><span class="line">	<span class="comment">// using number of blocks.</span></span><br><span class="line">	<span class="comment">// The grid dimension must be a multiple of cluster size.</span></span><br><span class="line">	cluster_kernel&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(input, output);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>线程块集群大小也可以在运行时设置，并且可以使用CUDA内核启动API
<code>cudaLaunchKernelEx</code>来启动内核。下面的代码示例展示了如何使用可扩展API来启动集群内核。</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Kernel definition</span></span><br><span class="line"><span class="comment">// No compile time attribute attached to the kernel</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">cluster_kernel</span><span class="params">(<span class="type">float</span> *input, <span class="type">float</span>* output)</span> </span>{</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">	<span class="type">float</span> *input, *output;</span><br><span class="line">	<span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span></span>;</span><br><span class="line">	<span class="function">dim3 <span class="title">numBlocks</span><span class="params">(N ∕ threadsPerBlock.x, N ∕ threadsPerBlock.y)</span></span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Kernel invocation with runtime cluster size</span></span><br><span class="line">	{</span><br><span class="line">	cudaLaunchConfig_t config = {<span class="number">0</span>};</span><br><span class="line">	<span class="comment">// The grid dimension is not affected by cluster launch, and is still enumerated</span></span><br><span class="line">	<span class="comment">// using number of blocks.</span></span><br><span class="line">	<span class="comment">// The grid dimension should be a multiple of cluster size.</span></span><br><span class="line">	config.gridDim = numBlocks;</span><br><span class="line">	config.blockDim = threadsPerBlock;</span><br><span class="line">	</span><br><span class="line">	cudaLaunchAttribute attribute[<span class="number">1</span>];</span><br><span class="line">	attribute[<span class="number">0</span>].id = cudaLaunchAttributeClusterDimension;</span><br><span class="line">	attribute[<span class="number">0</span>].val.clusterDim.x = <span class="number">2</span>; <span class="comment">// Cluster size in X-dimension</span></span><br><span class="line">	attribute[<span class="number">0</span>].val.clusterDim.y = <span class="number">1</span>;</span><br><span class="line">	attribute[<span class="number">0</span>].val.clusterDim.z = <span class="number">1</span>;</span><br><span class="line">	config.attrs = attribute;</span><br><span class="line">	config.numAttrs = <span class="number">1</span>;</span><br><span class="line">	</span><br><span class="line">	<span class="built_in">cudaLaunchKernelEx</span>(&amp;config, cluster_kernel, input, output);</span><br><span class="line">	}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>在具备计算能力9.0的GPU上，集群中的所有线程块都保证在单个GPU处理簇（GPC）上共同调度，这使得线程块之间可以进行高效的协作。这些线程块能够使用集群组API&nbsp;<code>cluster.sync()</code>&nbsp;执行硬件支持的同步操作。集群组API还提供了以下成员函数来查询集群组的大小：</p>
<ul>
<li><code>num_threads()</code>：这个API返回集群组中的总线程数。</li>
<li><code>num_blocks()</code>：这个API返回集群组中的总线程块数。</li>
</ul>
<p>此外，可以查询集群组中线程或块的排名，使用以下API：</p>
<ul>
<li><code>dim_threads()</code>：这个API用于查询当前线程在集群组中的排名。</li>
<li><code>dim_blocks()</code>：这个API用于查询当前线程块在集群组中的排名。</li>
</ul>
<p>属于一个集群的线程块有权访问分布式共享内存（Distributed Shared
Memory）。在集群中的线程块具有以下能力：</p>
<ul>
<li>读取分布式共享内存中的任何地址。</li>
<li>写入分布式共享内存中的任何地址。</li>
<li>在分布式共享内存中的任何地址上执行原子操作。</li>
</ul>
<p>分布式共享内存的一个示例应用是执行直方图统计。在这种应用中，集群中的每个线程块可以负责直方图的一部分，并将结果写入分布式共享内存。由于线程块之间可以高效地同步和共享数据，因此可以快速地完成整个直方图的计算。这种内存模型特别适合于需要大量线程间协作的计算任务，如数据并行处理、图像处理和某些类型的机器学习算法。</p>
<h2 id="memory-hierarchy">Memory Hierarchy</h2>
<p>CUDA线程在执行过程中可以从多个内存空间访问数据，如图所示。每个线程都有私有的本地内存。每个线程块都有共享内存，该共享内存对于块内的所有线程可见，并且与块具有相同的生命周期。线程块集群中的线程块可以对彼此的共享内存执行读、写和原子操作。所有线程都可以访问相同的全局内存。</p>
<p>还有两个额外的只读内存空间可供所有线程访问：常量和纹理内存空间。全局、常量和纹理内存空间针对不同的内存使用进行了优化（请参见设备内存访问）。纹理内存还为某些特定数据格式提供了不同的寻址模式，以及数据过滤（请参见纹理和表面内存）。全局、常量和纹理内存空间在相同应用程序启动内核期间是持久的。</p>
<p><img lazyload="" alt="image" data-src="https://github.com/amor-mio-de-mi-vida/picx-images-hosting/raw/master/cuda/image.60u8gmifgj.webp"></p>
<h2 id="heterogeneous-programming">Heterogeneous Programming</h2>
<p>CUDA编程模型假设CUDA线程在一个物理上独立的设备上执行，该设备作为运行C++程序的主机的协处理器。例如，当内核在GPU上执行，而C++程序的其他部分在CPU上执行时，就是这种情况。</p>
<p>CUDA编程模型还假设主机和设备各自在DRAM中维护自己的独立内存空间，分别称为主机内存和设备内存。因此，程序通过调用CUDA运行时（在编程接口中描述）来管理内核可见的全局、常量和纹理内存空间。这包括设备内存的分配和释放以及主机与设备内存之间的数据传输。</p>
<p>统一内存提供了托管内存，以桥接主机和设备内存空间。托管内存可以从系统中的所有CPU和GPU作为单个、连贯的内存镜像访问，具有共同的地址空间。这种能力使得设备内存超量分配成为可能，并且可以通过消除在主机和设备上显式镜像数据的需求，极大地简化应用程序移植的任务。有关统一内存的介绍，请参见统一内存编程。</p>
<h2 id="asynchronous-simt-programming-model">Asynchronous SIMT
Programming Model</h2>
<p>在CUDA编程模型中，线程是进行计算或内存操作的最底层抽象。从基于NVIDIA安培GPU架构的设备开始，CUDA编程模型通过异步编程模型为内存操作提供加速。异步编程模型定义了异步操作相对于CUDA线程的行为。</p>
<p>异步编程模型定义了异步屏障（Asynchronous
Barrier）的行为，用于CUDA线程之间的同步。该模型还解释并定义了如何使用cuda::memcpy_async在GPU计算的同时从全局内存异步移动数据。</p>
<h3 id="asynchronous-operations">Asynchronous Operations&nbsp;</h3>
<p>异步操作是指由CUDA线程发起的操作，该操作似乎是由另一个线程异步执行。在结构良好的程序中，一个或多个CUDA线程将与异步操作同步。发起异步操作的CUDA线程不一定需要是同步线程之一。&nbsp;这样的异步线程（假设的线程）总是与发起异步操作的CUDA线程相关联。异步操作使用同步对象来同步操作的完成。这样的同步对象可以由用户显式管理（例如，<code>cuda::memcpy_async</code>），也可以在库内部隐式管理（例如，<code>cooperative_groups::memcpy_async</code>）。&nbsp;同步对象可以是<code>cuda::barrier</code>或<code>cuda::pipeline</code>。这些对象在异步屏障和<code>cuda::pipeline</code>的异步数据复制中有详细说明。这些同步对象可以在不同的线程作用域中使用。作用域定义了可以使用同步对象与异步操作同步的线程集合。以下表格定义了CUDA
C++中可用的线程作用域以及可以与每个作用域同步的线程：</p>
<p><img lazyload="" alt="image" data-src="https://github.com/amor-mio-de-mi-vida/picx-images-hosting/raw/master/cuda/image.2a52ve39sq.webp"></p>
<h1 id="programming-interface">Programming Interface</h1>
<p>CUDA
C++为熟悉C++编程语言的用户提供了一条简单的路径，可以轻松地为设备编写程序。&nbsp;它包括对C++语言的最小集合扩展和一个运行时库。</p>
<h2 id="compilation-with-nvcc">Compilation with NVCC</h2>
<p>内核可以使用称为PTX的CUDA指令集架构来编写，这在PTX参考手册中有描述。然而，通常使用像C++这样的高级编程语言会更有效。在这两种情况下，内核必须通过nvcc编译成二进制代码才能在设备上执行。</p>
<p>nvcc是一个编译器驱动程序，它简化了编译C++或PTX代码的过程：它提供了简单且熟悉的命令行选项，并通过调用实现不同编译阶段的工具集合来执行这些选项。本节概述了nvcc的工作流程和命令选项。完整的描述可以在nvcc用户手册中找到。</p>
<h3 id="compilation-workflow">Compilation Workflow</h3>
<h4 id="offline-compilation">Offline Compilation</h4>
<p>使用nvcc编译的源文件可以包含主机代码（即，在主机上执行的代码）和设备代码（即，在设备上执行的代码）的混合。nvcc的基本工作流程包括从主机代码中分离设备代码，然后执行以下步骤：</p>
<ul>
<li><p>将设备代码编译成汇编形式（PTX代码）和/或二进制形式（cubin对象），&nbsp;</p></li>
<li><p>通过替换在内核中引入的&lt;&lt;&lt;…&gt;&gt;&gt;语法（在执行配置中更详细描述）来修改主机代码，替换为必要的CUDA运行时函数调用，以从PTX代码和/或cubin对象加载和启动每个编译后的内核。</p></li>
</ul>
<p>修改后的主机代码可以输出为C++代码，留待使用其他工具编译，或者直接输出为对象代码，通过在最后编译阶段让nvcc调用主机编译器。</p>
<p>应用程序然后可以执行以下操作：</p>
<ul>
<li><p>或者链接到编译后的主机代码（这是最常见的情况），</p></li>
<li><p>或者忽略修改后的主机代码（如果有的话）并使用CUDA驱动API（参见驱动API）来加载和执行PTX代码或cubin对象。</p></li>
</ul>
<h4 id="just-in-time-compilation">Just-in-Time Compilation</h4>
<p>应用程序在运行时加载的任何PTX代码都会由设备驱动程序进一步编译成二进制代码，这个过程称为即时编译。即时编译会增加应用程序的加载时间，但允许应用程序利用每次新设备驱动程序带来的编译器改进。这也是应用程序在编译时还不存在的设备上运行的唯一方式，详细内容请参见应用程序兼容性。</p>
<p>当设备驱动程序为某个应用程序即时编译一些PTX代码时，它会自动缓存生成的二进制代码的副本，以避免在应用程序的后续调用中重复编译。这个缓存被称为计算缓存，当设备驱动程序升级时，计算缓存会自动失效，以便应用程序可以从设备驱动程序内置的新即时编译器的改进中受益。</p>
<p>环境变量可用于控制即时编译，具体描述请参见CUDA环境变量。</p>
<p>作为使用nvcc编译CUDA
C++设备代码的替代方案，NVRTC可以在运行时用于将CUDA
C++设备代码编译成PTX。NVRTC是一个用于CUDA
C++的运行时编译库；更多信息可以在NVRTC用户指南中找到。</p>
<h3 id="binary-compatibility">Binary Compatibility</h3>
<p>二进制代码是特定于架构的。cubin对象是通过使用编译器选项<code>-code</code>来生成的，该选项指定了目标架构：例如，使用<code>-code=sm_80</code>进行编译会为计算能力为8.0的设备生成二进制代码。从一个小版本到下一个版本的二进制兼容性是有保证的，但是从一个小版本到前一个版本或者跨主要版本则没有保证。换句话说，为计算能力X.y生成的cubin对象只能在计算能力为X.z的设备上执行，其中z
≥ y。</p>
<h3 id="ptx-compatibility">PTX Compatibility</h3>
<p>一些PTX指令只在计算能力较高的设备上支持。例如，Warp
Shuffle函数仅在计算能力为5.0及以上的设备上支持。编译器选项<code>-arch</code>用于指定在将C++代码编译为PTX代码时假设的计算能力。因此，例如包含warp
shuffle的代码必须使用<code>-arch=compute_50</code>（或更高）进行编译。为特定计算能力生成的PTX代码总是可以编译为更大或等于该计算能力的二进制代码。</p>
<p>请注意，从早期PTX版本编译的二进制文件可能不会使用某些硬件特性。例如，针对计算能力为7.0（Volta）的设备编译的二进制文件，如果是从为计算能力6.0（Pascal）生成的PTX编译的，将不会使用Tensor
Core指令，因为这些在Pascal上不可用。因此，最终的二进制文件可能性能不如使用最新版本PTX生成的二进制文件。</p>
<p>编译为目标架构条件特征的PTX代码只在完全相同的物理架构上运行，而在其他地方则不会运行。架构条件PTX代码不具备向前和向后兼容性。例如，使用sm_90a或compute_90a编译的代码只在计算能力为9.0的设备上运行，并且不具备向后或向前兼容性。</p>
<h2 id="cuda-runtime">CUDA Runtime</h2>
<p>运行时是在cudart库中实现的，该库与应用程序链接，可以是静态链接通过cudart.lib或libcudart.a，也可以是动态链接通过cudart.dll或libcudart.so。需要cudart.dll和/或libcudart.so进行动态链接的应用程序通常将它们作为应用程序安装包的一部分包含。只有当组件链接到同一实例的CUDA运行时时，传递CUDA运行时符号的地址才是安全的。它的所有入口点都以前缀cuda开头。</p>
<h3 id="initialization">Initialization</h3>
<p>从CUDA
12.0开始，<code>cudaInitDevice()</code>和<code>cudaSetDevice()</code>调用用于初始化运行时和与指定设备关联的主上下文。如果没有这些调用，运行时会隐式使用设备0，并根据需要自行初始化以处理其他运行时API请求。在计时运行时函数调用和解释第一次调用运行时返回的错误代码时，需要记住这一点。在12.0之前，<code>cudaSetDevice()</code>不会初始化运行时，应用程序通常会使用无操作的运行时调用<code>cudaFree(0)</code>来将运行时初始化与其他API活动隔离开（这样做既是为了计时，也是为了错误处理）。</p>
<p>运行时为系统中的每个设备创建一个CUDA上下文。这个上下文是该设备的主上下文，在第一次需要在此设备上激活上下文的运行时函数时被初始化。它被应用程序的所有主机线程共享。作为上下文创建的一部分，如果需要，设备代码会被即时编译并加载到设备内存中。这一切都是透明发生的。如果需要，例如，为了与驱动API互操作，可以通过驱动API访问设备的主上下文。</p>
<p>当主机线程调用<code>cudaDeviceReset()</code>时，这会销毁主机线程当前操作的设备的主上下文（即，如设备选择中定义的当前设备）。任何将此设备作为当前设备的主机线程进行的下一次运行时函数调用都会为该设备创建一个新的主上下文。</p>
<h3 id="device-memory">Device Memory</h3>
<p>CUDA编程模型假设系统由主机和设备组成，每个都有自己的独立内存。内核在设备内存中操作，因此运行时提供了用于分配、释放和复制设备内存的函数，以及用于在主机内存和设备内存之间传输数据的函数。</p>
<p>设备内存可以分配为线性内存或CUDA数组。</p>
<p>CUDA数组是为纹理提取优化的不透明内存布局。</p>
<p>线性内存是在单个统一地址空间中分配的，这意味着单独分配的实体可以通过指针相互引用，例如，在二叉树或链表中。地址空间的大小取决于主机系统（CPU）和使用GPU的计算能力：</p>
<p>线性内存分配是通过<code>cudaMalloc()</code>函数进行的，而释放是通过<code>cudaFree()</code>函数。数据在主机内存和设备内存之间的传输是通过<code>cudaMemcpy()</code>函数系列来完成的，这些函数支持各种传输模式，包括主机到设备、设备到主机以及设备到设备的传输。</p>
<p>在CUDA中，线性内存通常使用<code>cudaMalloc()</code>来分配，使用<code>cudaFree()</code>来释放。主机内存与设备内存之间的数据传输通常使用<code>cudaMemcpy()</code>来完成。在《Kernels》部分的向量加法代码示例中，需要将向量从主机内存复制到设备内存。</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Device code</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">VecAdd</span><span class="params">(<span class="type">float</span>* A, <span class="type">float</span>* B, <span class="type">float</span>* C, <span class="type">int</span> N)</span> </span>{</span><br><span class="line">	<span class="type">int</span> i = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">	<span class="keyword">if</span> (i &lt; N)</span><br><span class="line">	C[i] = A[i] + B[i];</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// Host code</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">	<span class="type">int</span> N = ...;</span><br><span class="line">	<span class="type">size_t</span> size = N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Allocate input vectors h_A and h_B in host memory</span></span><br><span class="line">	<span class="type">float</span>* h_A = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line">	<span class="type">float</span>* h_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line">	<span class="type">float</span>* h_C = (<span class="type">float</span>*)<span class="built_in">malloc</span>(size);</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Initialize input vectors</span></span><br><span class="line">	...</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Allocate vectors in device memory</span></span><br><span class="line">	<span class="type">float</span>* d_A;</span><br><span class="line">	<span class="built_in">cudaMalloc</span>(&amp;d_A, size);</span><br><span class="line">	<span class="type">float</span>* d_B;</span><br><span class="line">	<span class="built_in">cudaMalloc</span>(&amp;d_B, size);</span><br><span class="line">	<span class="type">float</span>* d_C;</span><br><span class="line">	<span class="built_in">cudaMalloc</span>(&amp;d_C, size);</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Copy vectors from host memory to device memory</span></span><br><span class="line">	<span class="built_in">cudaMemcpy</span>(d_A, h_A, size, cudaMemcpyHostToDevice);</span><br><span class="line">	<span class="built_in">cudaMemcpy</span>(d_B, h_B, size, cudaMemcpyHostToDevice);</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Invoke kernel</span></span><br><span class="line">	<span class="type">int</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line">	<span class="type">int</span> blocksPerGrid = (N + threadsPerBlock - <span class="number">1</span>) ∕ threadsPerBlock;</span><br><span class="line">	VecAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Copy result from device memory to host memory</span></span><br><span class="line">	<span class="comment">// h_C contains the result in host memory</span></span><br><span class="line">	<span class="built_in">cudaMemcpy</span>(h_C, d_C, size, cudaMemcpyDeviceToHost);</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Free device memory</span></span><br><span class="line">	<span class="built_in">cudaFree</span>(d_A);</span><br><span class="line">	<span class="built_in">cudaFree</span>(d_B);</span><br><span class="line">	<span class="built_in">cudaFree</span>(d_C);</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Free host memory</span></span><br><span class="line">	...</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><code>cudaMallocPitch()</code>&nbsp;和&nbsp;<code>cudaMalloc3D()</code>&nbsp;函数用于分配二维或三维数组，它们确保分配的内存适当地填充以满足《设备内存访问》中描述的对齐要求，从而在访问行地址或使用&nbsp;<code>cudaMemcpy2D()</code>&nbsp;和&nbsp;<code>cudaMemcpy3D()</code>&nbsp;函数在二维数组与其他设备内存区域之间执行复制时确保最佳性能。返回的跨度（或步幅）必须用于访问数组元素。
</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Host code</span></span><br><span class="line"><span class="type">int</span> width = <span class="number">64</span>, height = <span class="number">64</span>;</span><br><span class="line"><span class="type">float</span>* devPtr;</span><br><span class="line"><span class="type">size_t</span> pitch;</span><br><span class="line"><span class="built_in">cudaMallocPitch</span>(&amp;devPtr, &amp;pitch, width * <span class="built_in">sizeof</span>(<span class="type">float</span>), height);</span><br><span class="line">MyKernel&lt;&lt;&lt;<span class="number">100</span>, <span class="number">512</span>&gt;&gt;&gt;(devPtr, pitch, width, height);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Device code</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MyKernel</span><span class="params">(<span class="type">float</span>* devPtr, <span class="type">size_t</span> pitch, <span class="type">int</span> width, <span class="type">int</span> height)</span> </span>{</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> r = <span class="number">0</span>; r &lt; height; ++r) {</span><br><span class="line">		<span class="type">float</span>* row = (<span class="type">float</span>*)((<span class="type">char</span>*)devPtr + r * pitch);</span><br><span class="line">		<span class="keyword">for</span> (<span class="type">int</span> c = <span class="number">0</span>; c &lt; width; ++c) {</span><br><span class="line">			<span class="type">float</span> element = row[c];</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>以下代码示例分配了一个宽度 x 高度 x
深度的浮点值三维数组，并展示了如何在设备代码中遍历数组元素：
</p><figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Host code</span></span><br><span class="line"><span class="type">int</span> width = <span class="number">64</span>, height = <span class="number">64</span>, depth = <span class="number">64</span>;</span><br><span class="line">cudaExtent extent = <span class="built_in">make_cudaExtent</span>(width * <span class="built_in">sizeof</span>(<span class="type">float</span>), height, depth);</span><br><span class="line">cudaPitchedPtr devPitchedPtr;</span><br><span class="line"><span class="built_in">cudaMalloc3D</span>(&amp;devPitchedPtr, extent);</span><br><span class="line">MyKernel&lt;&lt;&lt;<span class="number">100</span>, <span class="number">512</span>&gt;&gt;&gt;(devPitchedPtr, width, height, depth);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Device code</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MyKernel</span><span class="params">(cudaPitchedPtr devPitchedPtr, <span class="type">int</span> width, <span class="type">int</span> height, <span class="type">int</span> depth)</span> </span>{</span><br><span class="line">	<span class="type">char</span>* devPtr = devPitchedPtr.ptr;</span><br><span class="line">	<span class="type">size_t</span> pitch = devPitchedPtr.pitch;</span><br><span class="line">	<span class="type">size_t</span> slicePitch = pitch * height;</span><br><span class="line">	<span class="keyword">for</span> (<span class="type">int</span> z = <span class="number">0</span>; z &lt; depth; ++z) {</span><br><span class="line">		<span class="type">char</span>* slice = devPtr + z * slicePitch;</span><br><span class="line">		<span class="keyword">for</span> (<span class="type">int</span> y = <span class="number">0</span>; y &lt; height; ++y) {</span><br><span class="line">			<span class="type">float</span>* row = (<span class="type">float</span>*)(slice + y * pitch);</span><br><span class="line">			<span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x &lt; width; ++x) {</span><br><span class="line">				<span class="type">float</span> element = row[x];</span><br><span class="line">			}</span><br><span class="line">		}</span><br><span class="line">	}</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>为了避免分配过多内存从而影响系统范围内的性能，可以根据问题大小从用户那里请求分配参数。如果分配失败，您可以回退到其他较慢的内存类型（<code>cudaMallocHost()</code>、<code>cudaHostRegister()</code>等），或者返回一个错误，告诉用户需要多少内存被拒绝了。如果您的应用程序由于某种原因无法请求分配参数，我们建议对于支持的平台使用
<code>cudaMallocManaged()</code>。</p>
<p>参考手册列出了所有用于在以下内存之间复制数据的各种函数：使用
<code>cudaMalloc()</code>分配的线性内存、使用
<code>cudaMallocPitch()</code>或<code>cudaMalloc3D()</code>分配的线性内存、CUDA
数组，以及为在全局或常量内存空间中声明的变量分配的内存。以下代码示例展示了通过运行时
API 访问全局变量的不同方式：</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">__constant__ <span class="type">float</span> constData[<span class="number">256</span>];</span><br><span class="line"><span class="type">float</span> data[<span class="number">256</span>];</span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaMemcpyToSymbol</span>(constData, data, <span class="built_in">sizeof</span>(data));</span><br><span class="line"><span class="built_in">cudaMemcpyFromSymbol</span>(data, constData, <span class="built_in">sizeof</span>(data));</span><br><span class="line"></span><br><span class="line">__device__ <span class="type">float</span> devData;</span><br><span class="line"><span class="type">float</span> value = <span class="number">3.14f</span>;</span><br><span class="line"><span class="built_in">cudaMemcpyToSymbol</span>(devData, &amp;value, <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"></span><br><span class="line">__device__ <span class="type">float</span>* devPointer;</span><br><span class="line"><span class="type">float</span>* ptr;</span><br><span class="line"><span class="built_in">cudaMalloc</span>(&amp;ptr, <span class="number">256</span> * <span class="built_in">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"><span class="built_in">cudaMemcpyToSymbol</span>(devPointer, &amp;ptr, <span class="built_in">sizeof</span>(ptr));</span><br></pre></td></tr></tbody></table></figure>
<p><code>cudaGetSymbolAddress()</code>
用于检索指向在全局内存空间中声明的变量所分配内存的地址。通过
<code>cudaGetSymbolSize()</code>获取已分配内存的大小。</p>
<h3 id="device-memory-l2-access-management">Device Memory L2 Access
Management</h3>
<p>当CUDA内核重复访问全局内存中的数据区域时，这样的数据访问可以被认为是持久的。另一方面，如果数据只被访问一次，这样的数据访问可以被认为是流式的。</p>
<p>从CUDA
11.0开始，计算能力为8.0及以上的设备具有影响L2缓存中数据持久性的能力，这可能会提高访问全局内存的带宽并降低延迟。</p>
<h4 id="l2-cache-set-aside-for-persisting-accesses">L2 Cache Set-Aside
for Persisting Accesses</h4>
<p>可以将L2缓存的一部分设置保留，用于持久访问全局内存。持久访问将优先使用这部分保留的L2缓存，而普通或流式访问全局内存只能在持久访问未使用这部分L2缓存时使用它。持久访问的L2缓存保留大小可以在一定范围内进行调整。</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaGetDeviceProperties</span>(&amp;prop, device_id);</span><br><span class="line"><span class="type">size_t</span> size = <span class="built_in">min</span>(<span class="built_in">int</span>(prop.l2CacheSize * <span class="number">0.75</span>), prop.persistingL2CacheMaxSize);</span><br><span class="line"><span class="built_in">cudaDeviceSetLimit</span>(cudaLimitPersistingL2CacheSize, size); <span class="comment">/* set-aside 3∕4 of L2 cachefor persisting accesses or the max allowed */</span></span><br></pre></td></tr></tbody></table></figure>
<p>当GPU配置为多实例GPU（MIG）模式时，L2缓存保留功能将被禁用。在使用多进程服务（MPS）时，不能通过cudaDeviceSetLimit更改L2缓存的保留大小。相反，保留大小只能在启动MPS服务器时通过环境变量CUDA_DEVICE_DEFAULT_PERSISTING_L2_CACHE_PERCENTAGE_LIMIT指定。</p>
<h4 id="l2-policy-for-persisting-accesses">L2 Policy for Persisting
Accesses</h4>
<p>访问策略窗口指定全局内存中的一个连续区域以及该区域内访问的L2缓存中的持久性属性。以下代码示例展示了如何使用CUDA流设置一个L2持久访问窗口：</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cudaStreamAttrValue stream_attribute;</span><br><span class="line"><span class="comment">//Stream level attributes data structure</span></span><br><span class="line">stream_attribute.accessPolicyWindow.base_ptr = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">void</span>*&gt;(ptr); </span><br><span class="line"><span class="comment">//Global Memory data pointer </span></span><br><span class="line">stream_attribute.accessPolicyWindow.num_bytes = num_bytes;</span><br><span class="line"><span class="comment">// Number of bytes for persistence access.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// (Must be less than cudaDeviceProp::accessPolicyMaxWindowSize)</span></span><br><span class="line">stream_attribute.accessPolicyWindow.hitRatio = <span class="number">0.6</span>;</span><br><span class="line"><span class="comment">// Hint for cache hit ratio</span></span><br><span class="line">stream_attribute.accessPolicyWindow.hitProp= cudaAccessPropertyPersisting; </span><br><span class="line"><span class="comment">// Type of access property on cache hit</span></span><br><span class="line">stream_attribute.accessPolicyWindow.missProp = cudaAccessPropertyStreaming; </span><br><span class="line"><span class="comment">// Type of access property on cache miss.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Set the attributes to a CUDA stream of type cudaStream_t</span></span><br><span class="line"><span class="built_in">cudaStreamSetAttribute</span>(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);</span><br></pre></td></tr></tbody></table></figure>
<p>当随后在CUDA流中执行内核时，位于全局内存范围
<code>[ptr…ptr+num_bytes)</code>内的内存访问比访问其他全局内存位置更有可能保留在L2缓存中。</p>
<p>L2持久性也可以为CUDA图内核节点设置，如下例所示：</p>
<figure class="highlight c++"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cudaKernelNodeAttrValue node_attribute;</span><br><span class="line"><span class="comment">// Kernellevel attributes data structure</span></span><br><span class="line">node_attribute.accessPolicyWindow.base_ptr = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">void</span>*&gt;(ptr); </span><br><span class="line"><span class="comment">// Global Memory data pointer</span></span><br><span class="line">node_attribute.accessPolicyWindow.num_bytes = num_bytes;</span><br><span class="line"><span class="comment">// Number of bytes for persistence access.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// (Must be less than cudaDeviceProp::accessPolicyMaxWindowSize)</span></span><br><span class="line">node_attribute.accessPolicyWindow.hitRatio = <span class="number">0.6</span>;</span><br><span class="line"><span class="comment">// Hint for cache hit ratio</span></span><br><span class="line">node_attribute.accessPolicyWindow.hitProp= cudaAccessPropertyPersisting; </span><br><span class="line"><span class="comment">// Type of access property on cache hit</span></span><br><span class="line">node_attribute.accessPolicyWindow.missProp = cudaAccessPropertyStreaming; </span><br><span class="line"><span class="comment">// Type of access property on cache miss.</span></span><br><span class="line"><span class="comment">// Set the attributes to a CUDA Graph Kernel node of type cudaGraphNode_t</span></span><br><span class="line"><span class="built_in">cudaGraphKernelNodeSetAttribute</span>(node, cudaKernelNodeAttributeAccessPolicyWindow, &amp;node_attribute);</span><br></pre></td></tr></tbody></table></figure>

                    
                </div>

                
                        
<div class="post-copyright-info-container border-box">
    <div class="copyright-info-content border-box">
        <div class="copyright-info-top border-box">
            <div class="copyright-post-title border-box text-ellipsis">
                Programming Model
            </div>

            <div class="copyright-post-link border-box text-ellipsis">
                2024/10/16/cuda-CUDA-C-Programming-Guide-Programming-Model/
            </div>
        </div>

        <div class="copyright-info-bottom border-box">
            <div class="copyright-post-author bottom-item">
                <div class="type">
                    Author
                </div>
                <div class="content">amor mío de mi vida</div>
            </div>

            <div class="post-time bottom-item">
                <div class="type">
                    Published
                </div>
                <div class="content">2024-10-16 20:35</div>
            </div>


            <div class="post-license bottom-item">
                <div class="type">
                    License
                </div>
                <div class="content tooltip" data-tooltip-content="CC BY-NC-SA 4.0">
                    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed" target="_blank">
                        
                            <i class="fa-brands fa-creative-commons"></i>
                            <i class="fa-brands fa-creative-commons-by"></i>
                            <i class="fa-brands fa-creative-commons-nc"></i>
                            <i class="fa-brands fa-creative-commons-sa"></i>
                        
                    </a>
                </div>
            </div>
        </div>

        <i class="copyright-bg fa-solid fa-copyright"></i>
    </div>
    <div class="copy-copyright-info flex-center tooltip" data-tooltip-content="Copy copyright info" data-tooltip-offset-y="-2px">
        <i class="fa-solid fa-copy"></i>
    </div>
</div>

                

                <div class="post-bottom-tags-and-share border-box">
                    <div>
                        
                    </div>
                    <div>
                        
                            <div class="post-share-container border-box">
    <ul class="share-list-wrap border-box">
        <li class="qq share-item border-box flex-center tooltip" data-tooltip-content="Share to QQ">
            <i class="fa-brands fa-qq"></i>
        </li>
        <li class="wechat share-item border-box flex-center tooltip tooltip-img" data-tooltip-content="Share to WeChat" data-tooltip-img-tip="Scan by WeChat" data-tooltip-img-style="background-color: #fff; top: -10px; padding: 0.6rem 0.6rem 0.1rem 0.6rem;">
            <i class="fa-brands fa-weixin"></i>
        </li>
        <li class="weibo share-item border-box flex-center tooltip" data-tooltip-content="Share to WeiBo">
            <i class="fa-brands fa-weibo"></i>
        </li>
    </ul>
</div>

                        
                    </div>
                </div>

                

                
                    <div class="post-nav border-box">
                        
                            <div class="prev-post">
                                <a class="prev" rel="prev" href="/2024/10/16/book-Mastering-Your-PhD/" title="Mastering Your PhD">
                                    <span class="left arrow-icon flex-center">
                                        <i class="fas fa-chevron-left"></i>
                                    </span>
                                    <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">Mastering Your PhD</span>
                                        <span class="post-nav-item">Prev posts</span>
                                    </span>
                                </a>
                            </div>
                        
                        
                            <div class="next-post">
                                <a class="next" rel="next" href="/2024/10/16/course-DLSystem-3-Automatic-Differentiation/" title="Automatic Differentiation">
                                    <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">Automatic Differentiation</span>
                                        <span class="post-nav-item">Next posts</span>
                                    </span>
                                    <span class="right arrow-icon flex-center">
                                        <i class="fas fa-chevron-right"></i>
                                    </span>
                                </a>
                            </div>
                        
                    </div>
                

                
                    






                
            </div>
        </div>

        
            <div class="pc-post-toc right-toc">
                <div class="post-toc-wrap border-box">
    <div class="post-toc border-box">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#programming-model"><span class="nav-text">Programming Model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#kernels"><span class="nav-text">Kernels</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#thread-hierarchy"><span class="nav-text">Thread Hierarchy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#memory-hierarchy"><span class="nav-text">Memory Hierarchy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#heterogeneous-programming"><span class="nav-text">Heterogeneous Programming</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#asynchronous-simt-programming-model"><span class="nav-text">Asynchronous SIMT
Programming Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#asynchronous-operations"><span class="nav-text">Asynchronous Operations&nbsp;</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#programming-interface"><span class="nav-text">Programming Interface</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#compilation-with-nvcc"><span class="nav-text">Compilation with NVCC</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#compilation-workflow"><span class="nav-text">Compilation Workflow</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#offline-compilation"><span class="nav-text">Offline Compilation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#just-in-time-compilation"><span class="nav-text">Just-in-Time Compilation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#binary-compatibility"><span class="nav-text">Binary Compatibility</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ptx-compatibility"><span class="nav-text">PTX Compatibility</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda-runtime"><span class="nav-text">CUDA Runtime</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#initialization"><span class="nav-text">Initialization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#device-memory"><span class="nav-text">Device Memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#device-memory-l2-access-management"><span class="nav-text">Device Memory L2 Access
Management</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#l2-cache-set-aside-for-persisting-accesses"><span class="nav-text">L2 Cache Set-Aside
for Persisting Accesses</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#l2-policy-for-persisting-accesses"><span class="nav-text">L2 Policy for Persisting
Accesses</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>
        </div>

        <div class="page-main-content-bottom border-box">
            
<footer class="footer border-box">
    <div class="copyright-info info-item">
        ©&nbsp;<span>2020</span>&nbsp;-&nbsp;2024
        
            &nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;&nbsp;<a href="/">amor mío de mi vida</a>
        
    </div>

    <div class="theme-info info-item">
        Powered by&nbsp;<a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;&amp;&nbsp;Theme&nbsp;<a class="keep-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep</a>
    </div>

    

    
        <div class="count-info info-item">
            

            
                <span class="count-item border-box uv">
                    <span class="item-type border-box">Unique Visitor</span>
                    <span class="item-value border-box uv" id="busuanzi_value_site_uv"></span>
                </span>
            

            
                <span class="count-item border-box pv">
                    <span class="item-type border-box">Page View</span>
                    <span class="item-value border-box pv" id="busuanzi_value_site_pv"></span>
                </span>
            
        </div>
    

    
</footer>

        </div>
    </div>

    <!-- post tools -->
    
        <div class="post-tools right-toc">
            <div class="post-tools-container border-box">
    <ul class="post-tools-list border-box">
        <!-- PC encrypt again -->
        

        <!-- PC TOC show toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- PC go comment -->
        

        <!-- PC full screen -->
        <li class="tools-item flex-center full-screen">
            <i class="fa-solid fa-expand"></i>
        </li>
    </ul>
</div>

        </div>
    

    <!-- side tools -->
    <div class="side-tools">
        <div class="side-tools-container border-box ">
    <ul class="side-tools-list side-tools-show-handle border-box">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <!-- toggle mode -->
        
            <li class="tools-item tool-toggle-theme-mode flex-center">
                <i class="fas fa-moon"></i>
            </li>
        

        <!-- rss -->
        

        <!-- to bottom -->
        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list border-box">
        
            <li class="tools-item toggle-show-toc-tablet flex-center">
                <i class="fas fa-list"></i>
            </li>
        

        

        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>

        <li class="tools-item tool-scroll-to-top flex-center show-arrow">
            <i class="arrow fas fa-arrow-up"></i>
            <span class="percent"></span>
        </li>
    </ul>
</div>

    </div>

    <!-- image mask -->
    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    <!-- local search -->
    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off" autocorrect="off" autocapitalize="off" placeholder="Search..." spellcheck="false" type="search" class="search-input">
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

    <!-- tablet toc -->
    
        <div class="tablet-post-toc-mask">
            <div class="tablet-post-toc">
                <div class="post-toc-wrap border-box">
    <div class="post-toc border-box">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#programming-model"><span class="nav-text">Programming Model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#kernels"><span class="nav-text">Kernels</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#thread-hierarchy"><span class="nav-text">Thread Hierarchy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#memory-hierarchy"><span class="nav-text">Memory Hierarchy</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#heterogeneous-programming"><span class="nav-text">Heterogeneous Programming</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#asynchronous-simt-programming-model"><span class="nav-text">Asynchronous SIMT
Programming Model</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#asynchronous-operations"><span class="nav-text">Asynchronous Operations&nbsp;</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#programming-interface"><span class="nav-text">Programming Interface</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#compilation-with-nvcc"><span class="nav-text">Compilation with NVCC</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#compilation-workflow"><span class="nav-text">Compilation Workflow</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#offline-compilation"><span class="nav-text">Offline Compilation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#just-in-time-compilation"><span class="nav-text">Just-in-Time Compilation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#binary-compatibility"><span class="nav-text">Binary Compatibility</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ptx-compatibility"><span class="nav-text">PTX Compatibility</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda-runtime"><span class="nav-text">CUDA Runtime</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#initialization"><span class="nav-text">Initialization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#device-memory"><span class="nav-text">Device Memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#device-memory-l2-access-management"><span class="nav-text">Device Memory L2 Access
Management</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#l2-cache-set-aside-for-persisting-accesses"><span class="nav-text">L2 Cache Set-Aside
for Persisting Accesses</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#l2-policy-for-persisting-accesses"><span class="nav-text">L2 Policy for Persisting
Accesses</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>
</div>

            </div>
        </div>
    
</main>





<!-- common js -->

<script src="/js/utils.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/toggle-theme.js"></script>

<script src="/js/code-block.js"></script>

<script src="/js/main.js"></script>

<script src="/js/libs/anime.min.js"></script>


<!-- local search -->

    
<script src="/js/local-search.js"></script>



<!-- lazyload -->

    
<script src="/js/lazyload.js"></script>



<div class="pjax">
    <!-- home page -->
    

    <!-- post page -->
    
        <!-- post-helper -->
        
<script src="/js/post/post-helper.js"></script>


        <!-- toc -->
        
            
<script src="/js/post/toc.js"></script>

        

        <!-- copyright-info -->
        
            
<script src="/js/post/copyright-info.js"></script>

        

        <!-- share -->
        
            
<script src="/js/post/share.js"></script>

        
    

    <!-- categories page -->
    

    <!-- links page -->
    

    <!-- photos page -->
    

    <!-- tools page -->
    
</div>

<!-- mermaid -->

    
<script src="//cdn.jsdelivr.net/npm/mermaid@10.5.0/dist/mermaid.min.js"></script>

    <script data-pjax="">
      if (window.mermaid) {
        mermaid.init()
      }
    </script>






<!-- pjax -->

    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart()
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd()
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'))
            KEEP.initExecute()
        });
    });
</script>






<script type="text/javascript" charset="utf-8" src="/js/lazyload-plugin/lazyload.intersectionObserver.min.js"></script></body></html>